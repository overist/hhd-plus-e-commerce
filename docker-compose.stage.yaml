# Docker Compose for Multi-Server Load Testing
# 10대 서버 + 1대 Redis 환경 시뮬레이션
#
# 사용법:
#   1. 앱 이미지 빌드: docker build -t hhplus-ecommerce .
#   2. 스케일 실행: docker compose -f docker-compose.stage.yaml up --scale app=10
#   3. K6 부하 테스트: k6 run k6/issue-coupon.script.js
#   4. 종료: docker compose -f docker-compose.stage.yaml down

services:
  # ============================================
  # Infrastructure
  # ============================================
  mysql:
    image: mysql:8.0
    container_name: scale-mysql
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: 'root1234!'
      MYSQL_DATABASE: ecommerce_db
      MYSQL_USER: docker
      MYSQL_PASSWORD: docker
      TZ: 'UTC'
    ports:
      - '3306:3306'
    volumes:
      - ./infra/initdb:/docker-entrypoint-initdb.d
    command:
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
    healthcheck:
      test: ['CMD', 'mysqladmin', 'ping', '-h', 'localhost']
      interval: 5s
      timeout: 300s
      retries: 100
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G

  # Redis (통합: 세션, 캐시, 분산락, NoSQL)
  redis:
    image: redis:8.4.0
    container_name: scale-redis
    restart: unless-stopped
    ports:
      - '6379:6379'
    command: redis-server --maxmemory 512mb --maxmemory-policy noeviction
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

  # Redis Seed (쿠폰 등 초기 데이터)
  redis-seed:
    image: redis:8.4.0
    container_name: scale-redis-seed
    restart: 'no'
    depends_on:
      redis:
        condition: service_healthy
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
    volumes:
      - ./infra/initredis/seed-coupons.sh:/seed/seed-coupons.sh:ro
    entrypoint:
      [
        '/bin/sh',
        '-c',
        'tr -d "\\r" < /seed/seed-coupons.sh > /tmp/seed.sh && sh /tmp/seed.sh',
      ]

  # Kafka Cluster (3 nodes)
  kafka-1:
    image: apache/kafka:3.7.0
    container_name: kafka-1
    ports:
      - '9094:9094'
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093

      - KAFKA_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_HOST://:9094,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-1:9092,PLAINTEXT_HOST://localhost:9094
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    volumes:
      - kafka_data_1:/tmp/kraft-combined-logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G

  kafka-2:
    image: apache/kafka:3.7.0
    container_name: kafka-2
    ports:
      - '9095:9095'
    environment:
      - KAFKA_NODE_ID=2
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093

      - KAFKA_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_HOST://:9095,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-2:9092,PLAINTEXT_HOST://localhost:9095
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    volumes:
      - kafka_data_2:/tmp/kraft-combined-logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G

  kafka-3:
    image: apache/kafka:3.7.0
    container_name: kafka-3
    ports:
      - '9096:9096'
    environment:
      - KAFKA_NODE_ID=3
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093

      - KAFKA_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_HOST://:9096,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-3:9092,PLAINTEXT_HOST://localhost:9096
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    volumes:
      - kafka_data_3:/tmp/kraft-combined-logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G

  # ============================================
  # Monitoring (Prometheus + Grafana)
  # ============================================
  prometheus:
    image: prom/prometheus:v2.54.1
    container_name: scale-prometheus
    restart: unless-stopped
    ports:
      - '9090:9090'
    volumes:
      - ./infra/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro

  grafana:
    image: grafana/grafana:11.3.0
    container_name: scale-grafana
    restart: unless-stopped
    ports:
      - '3001:3000'
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - ./infra/monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    command: ['--config=/etc/otel-collector-config.yaml']
    volumes:
      - ./infra/monitoring/otel/otel-config.yml:/etc/otel-collector-config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - '8889:8889'
    user: '0:0'

  # MySQL Exporter
  mysqld-exporter:
    image: prom/mysqld-exporter:v0.16.0
    container_name: scale-mysqld-exporter
    restart: unless-stopped
    command:
      - '--config.my-cnf=/etc/mysql_exporter/my.cnf'
    volumes:
      - ./infra/monitoring/mysql/my.cnf:/etc/mysql_exporter/my.cnf:ro
    depends_on:
      mysql:
        condition: service_healthy
    labels:
      prometheus_scrape: 'true'
      prometheus_job: 'mysql'
      prometheus_port: '9104'

  # Redis Exporter
  redis-exporter:
    image: oliver006/redis_exporter:v1.67.0
    container_name: scale-redis-exporter
    restart: unless-stopped
    environment:
      REDIS_ADDR: 'redis://redis:6379'
    depends_on:
      redis:
        condition: service_healthy
    labels:
      prometheus_scrape: 'true'
      prometheus_job: 'redis'
      prometheus_port: '9121'

  # Kafka Exporter
  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.8.0
    container_name: scale-kafka-exporter
    restart: unless-stopped
    command:
      - '--kafka.server=kafka-1:9092'
      - '--kafka.server=kafka-2:9092'
      - '--kafka.server=kafka-3:9092'
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    labels:
      prometheus_scrape: 'true'
      prometheus_job: 'kafka'
      prometheus_port: '9308'

  # ============================================
  # Load Balancer (Nginx)
  # ============================================
  nginx:
    image: nginx:alpine
    container_name: scale-nginx
    restart: unless-stopped
    ports:
      - '3000:80'
    volumes:
      - ./infra/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app

  # ============================================
  # Application (Scalable)
  # ============================================
  app:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      NODE_ENV: stage
      DATABASE_URL: 'mysql://docker:docker@mysql:3306/ecommerce_db'
      REDIS_URL: 'redis://redis:6379'
      SESSION_SECRET: 'scale-test-secret'
      PORT: 3000
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_CLIENT_ID: ecommerce-app
      KAFKA_GROUP_ID: ecommerce-app-group
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka-1:
        condition: service_started
      kafka-2:
        condition: service_started
      kafka-3:
        condition: service_started
    # 포트는 nginx가 로드밸런싱하므로 노출하지 않음
    expose:
      - '3000'
    deploy:
      # docker compose up --scale app=10 으로 오버라이드 가능
      replicas: 1
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

networks:
  default:
    name: scale-test-network

volumes:
  kafka_data_1:
  kafka_data_2:
  kafka_data_3:
